{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0d56898f-2d50-4b4e-9a5f-3dfa55fc2412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1 1\n",
      "1 0 0 1\n",
      "1 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 1\n",
      "0 1 0 1\n",
      "0 0 1 1\n",
      "0 0 1 1\n",
      "1 1 1 1\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "1 1 1 1\n",
      "0 1 0 1\n",
      "1 0 1 0\n",
      "1 1 0 0\n",
      "1 0 0 1\n",
      "0 1 0 1\n",
      "1 1 0 0\n",
      "1 1 0 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Create 3-input XOR training dataset..\n",
    "training_length = 6\n",
    "x_train = np.random.randint(0,2, size=(training_length,3),dtype=np.uint8)\n",
    "y_train=np.empty(training_length).astype(int)\n",
    "#x_train=np.array([[0,0,0],[0,0,1],[0,1,0],[1,1,0],[1,0,0],[1,0,1],[0,1,1],[1,1,1]])\n",
    "for i in range(training_length):\n",
    "  y_train[i]=(x_train[i][0]^x_train[i][1]^x_train[i][2])\n",
    "\n",
    "# for i in range(training_length):\n",
    "#     print(y_train[i], x_train[i][0], x_train[i][1], x_train[i][2])\n",
    "\n",
    "# Create 3-input XOR testing dataset...\n",
    "testing_length=20\n",
    "x_test = np.random.randint(0,2, size=(testing_length,3),dtype=np.uint8)\n",
    "y_test=np.empty(testing_length).astype(int)\n",
    "for i in range(testing_length):\n",
    "   y_test[i]=x_test[i][0]^x_test[i][1]^x_test[i][2]\n",
    "for i in range(testing_length):\n",
    "  y_test[i]=x_test[i][0]^x_test[i][1]^x_test[i][2]\n",
    "\n",
    "for i in range(testing_length):\n",
    "    print(y_test[i], x_test[i][0], x_test[i][1], x_test[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4d55cf9c-cc02-4ae1-8942-54b67ddee132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuresl(n):\n",
    "      c=[]\n",
    "      for i in range(n):\n",
    "        for j in range(2):\n",
    "          if j==0:\n",
    "            c.append(f'x{i+1}')\n",
    "          else:\n",
    "            c.append(f'~x{i+1}')\n",
    "      return c \n",
    "c=featuresl(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cb65b4e3-7cde-4b34-b42f-35b50ee32a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class tsetlinmachine:\n",
    "    def __init__(self,clauses,features,states,s,T):\n",
    "        # tsetlin machine hyperparameters.\n",
    "        self.clauses=clauses\n",
    "        self.features=features\n",
    "        self.states=states\n",
    "        self.s=s\n",
    "        self.T=T\n",
    "\n",
    "        # Initialize ta_state for each literal with minimum memory state.\n",
    "        self.ta_state=np.random.choice([states-1,states],size=(clauses,features,2))\n",
    "        \n",
    "        # Initialize clause things.\n",
    "        self.clauses_output=np.zeros(clauses)\n",
    "        self.clause_sign=np.zeros(clauses)\n",
    "        self.feedback=np.zeros(clauses)\n",
    "\n",
    "        # Assign polarity to clauses. +ve to even and -ve to odd. \n",
    "        for j in range(len(self.clause_sign)):\n",
    "            if j%2==0:\n",
    "                self.clause_sign[j]=+1\n",
    "            else:\n",
    "                self.clause_sign[j]=-1\n",
    "\n",
    "    # If literal lies in memory state assign 1 or else 0.\n",
    "    def action(self,state):\n",
    "        if state<=(self.states-1):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "            \n",
    "        # Returns clauses_output vector.\n",
    "    def clause_output(self):\n",
    "        return self.clauses_output\n",
    "        \n",
    "        # To get current TA state of a literal.\n",
    "    def get_state(self,clause,feature,l):\n",
    "        return self.ta_state[clause,feature,l]\n",
    "\n",
    "        # Calculates all the clauses output for a given literal vector X.\n",
    "    def get_clause_output(self,X):\n",
    "        for j in range(self.clauses):\n",
    "            self.clauses_output[j]=1\n",
    "            for k in range(self.features):\n",
    "                action_l=self.action(self.ta_state[j,k,0])\n",
    "                action_nl=self.action(self.ta_state[j,k,1])\n",
    "                if(action_l==1 and X[k]==0) or (action_nl==1 and X[k]==1):\n",
    "                    self.clauses_output[j]=0\n",
    "                    break\n",
    "        # Calculates class sum.\n",
    "    def get_class_sum(self):\n",
    "        sum=0\n",
    "        for j in range(self.clauses):\n",
    "            sum+=(self.clauses_output[j])*(self.clause_sign[j])\n",
    "        if sum > self.T:\n",
    "            sum=self.T\n",
    "        elif sum < -self.T:\n",
    "            sum=-self.T\n",
    "        return sum\n",
    "        \n",
    "        # Predicts class for given X.\n",
    "    def get_predicted_class(self,X):\n",
    "        self.get_clause_output(X)\n",
    "        if self.get_class_sum()>0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "# Training of Tsetlin machine\n",
    "\n",
    "    # Initialize feedback\n",
    "    def training(self,X,Y):\n",
    "        self.get_clause_output(X)\n",
    "        for j in range(self.clauses):\n",
    "            self.feedback[j]=0\n",
    "        if Y==1:\n",
    "            for j in range(self.clauses):\n",
    "                if random.random()>1.0*(self.T-self.get_class_sum())/(2*self.T):\n",
    "                    continue\n",
    "                elif j%2==0:\n",
    "                    self.feedback[j]=+1\n",
    "                else:\n",
    "                    self.feedback[j]=-1\n",
    "        else:\n",
    "            for j in range(self.clauses):\n",
    "                if random.random()>1.0*(self.T+self.get_class_sum())/(2*self.T):\n",
    "                    continue\n",
    "                elif j%2==0:\n",
    "                    self.feedback[j]=-1\n",
    "                else:\n",
    "                    self.feedback[j]=+1\n",
    "\n",
    "        # Giving feedback to clauses   \n",
    "        for j in range(self.clauses):\n",
    "            if self.feedback[j]>0:\n",
    "                #Type 1 feedback\n",
    "                if self.clauses_output[j]==1:\n",
    "                    #Recognize feedback\n",
    "                    for k in range(self.features):\n",
    "                       if X[k]==1:\n",
    "                          # if random.random()<=(self.s-1)/(self.s):\n",
    "                           if self.get_state(j,k,0)<self.states*2:\n",
    "                                   self.ta_state[j,k,0]+=1  # memorize literal kth x.\n",
    "                                   \n",
    "                           if random.random()<=(1/self.s):\n",
    "                               if self.get_state(j,k,1)>0:\n",
    "                                   self.ta_state[j,k,1]-=1  # forget literal kth x'.\n",
    "                                   \n",
    "                       elif X[k]==0:\n",
    "                           #if random.random()<=(self.s-1)/(self.s):\n",
    "                           if self.get_state(j,k,1)<self.states*2:\n",
    "                                   self.ta_state[j,k,1]+=1  # memorize literal kth x'.\n",
    "                                   \n",
    "                           if random.random()<=(1/self.s):\n",
    "                               if self.get_state(j,k,0)>0:\n",
    "                                   self.ta_state[j,k,0]-=1  # forget literal kth x.\n",
    "                                   \n",
    "                elif self.clauses_output[j]==0:\n",
    "                    #Erase feedback\n",
    "                    for k in range(self.features):\n",
    "                        if random.random()<=(1/self.s):\n",
    "                            if self.get_state(j,k,0)>0:\n",
    "                                self.ta_state[j,k,0]-=1\n",
    "                             \n",
    "                        if random.random()<=(1/self.s):\n",
    "                            if self.get_state(j,k,1)>0:\n",
    "                                self.ta_state[j,k,1]-=1\n",
    "                              \n",
    "         #Reject feedback\n",
    "        if self.feedback[j]<0:\n",
    "            if self.clauses_output[j]==1:\n",
    "                for k in range(self.features):\n",
    "                    action_l=self.action(self.get_state(j,k,0))\n",
    "                    action_nl=self.action(self.get_state(j,k,1))\n",
    "                    if action_l==0 and self.get_state(j,k,0)<self.states*2:\n",
    "                        self.ta_state[j,k,0]+=1                        \n",
    "                    if action_nl==0 and self.get_state(j,k,1)<self.states*2 :\n",
    "                        self.ta_state[j,k,1]+=1  # Try to include literals from excluded state to make clause output zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "727daebb-4d7c-428f-8e48-68b7f4d9ec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's training, yeah!\n"
     ]
    }
   ],
   "source": [
    "clauses = 11\n",
    "features = x_train.shape[1]\n",
    "states = 5\n",
    "s = 13\n",
    "T = 5\n",
    "epochs = 700\n",
    "print(\"It's training, yeah!\")\n",
    "MNIST_tm = tsetlinmachine(clauses,features,states,s,T) # Create object of class tsetlinmachine\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for i in range(x_train.shape[0]):\n",
    "        MNIST_tm.training(x_train[i],y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "85037bcc-87eb-442d-b280-46860855d23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acccuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# testing_length=20\n",
    "# x_test = np.random.randint(0,2, size=(testing_length,3),dtype=np.uint8)\n",
    "# y_test=np.empty(testing_length).astype(int)\n",
    "\n",
    " \n",
    "x_test=np.array([[0,1,1],[1,1,1]])\n",
    "\n",
    "for i in range(2):\n",
    "   y_test[i]=(x_test[i][0]^x_test[i][1]^x_test[i][2])\n",
    "correct_prediction = 0 \n",
    "\n",
    "total_predictions = x_test.shape[0]\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    prediction = MNIST_tm.get_predicted_class(x_test[i])\n",
    "    if prediction == y_test[i]:\n",
    "        correct_prediction +=1\n",
    "\n",
    "accuracy = correct_prediction / total_predictions\n",
    "print(f\"Test Acccuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "82dbc2ae-80f1-4f2f-b2ed-fbce385e29f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clause 0 : ['x1', 'x2', 'x3']\n",
      "clause 1 : ['~x1', '~x2', '~x3']\n",
      "clause 2 : ['~x1', 'x2', '~x3']\n",
      "clause 3 : ['~x1', 'x2', 'x3']\n",
      "clause 4 : ['~x1', 'x2', '~x3']\n",
      "clause 5 : ['~x1', '~x2', '~x3']\n",
      "clause 6 : ['~x1', '~x2', 'x3']\n",
      "clause 7 : ['~x1', 'x2', 'x3']\n",
      "clause 8 : ['~x1', '~x2', 'x3']\n",
      "clause 9 : ['~x1', 'x2', 'x3']\n",
      "clause 10 : ['x1', 'x2', 'x3']\n"
     ]
    }
   ],
   "source": [
    "def featuresl(n):\n",
    "      c=[]\n",
    "      for i in range(n):\n",
    "        for j in range(2):\n",
    "          if j==0:\n",
    "            c.append(f'x{i+1}')\n",
    "          else:\n",
    "            c.append(f'~x{i+1}')\n",
    "      return c \n",
    "c=featuresl(3)    \n",
    "for j in range(clauses):\n",
    "    for k in range(features):\n",
    "        for l in range(2):\n",
    "            if MNIST_tm.ta_state[j,k,l]>=states:\n",
    "                C.append(c[2*k+l]) \n",
    "    print(f'clause {j} :',C)        \n",
    "    C=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8652ab0b-bdb6-4648-84f2-b6aec73b65c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# #!pip install matplotlib\n",
    "# # Binary Classifier\n",
    "\n",
    "# (x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data() # Load MNIST dataset from keras\n",
    "\n",
    "# # Extract only images of integers 0 and 1, that is class-0 and class-1. \n",
    "# # x --> handwritten digits images, y--> respective labels.\n",
    "\n",
    "# class_0_train = x_train[y_train == 0]  #class-0 for training. shape(5923,28,28) each image is a matrix of 28 X 28\n",
    "# class_1_train = x_train[y_train == 1]  #class-1 for training. shape(6742,28,28) each image is a matrix of 28 X 28\n",
    "\n",
    "# class_0_test = x_test[y_test == 0]     #class-0 for testing. shape(980,28,28)\n",
    "# class_1_test = x_test[y_test == 1]     #class-1 for testing. shape(1135,28,28)\n",
    "\n",
    "# # Binarization function to binarize image w.r.t threshold.\n",
    "\n",
    "# def bin(image,threshold = 128):\n",
    "#     return np.where(image > 128,1,0)\n",
    "\n",
    "# class_0_train = bin(class_0_train)   #Binarize class-0 images\n",
    "# class_1_train = bin(class_1_train)   #Binarize class-1 images\n",
    "\n",
    "# class_0_train = class_0_train.reshape(class_0_train.shape[0],-1)  #Reshape 2D images to 1D array. shape(5923,784), arrays of features.\n",
    "# class_1_train = class_1_train.reshape(class_1_train.shape[0],-1)  #Reshape 2D images to 1D array. shape(6742,784), arrays of features.\n",
    "\n",
    "# # class_0_neg = 1-class_0_train  #Negated features.\n",
    "# # class_1_neg = 1-class_1_train  #Negated features.\n",
    "\n",
    "# # class_0_literals = np.concatenate((class_0_train,class_0_neg),axis = 1) #This is a full literal vector. shape(5923,1568)---784+784=1568.\n",
    "# # class_1_literals = np.concatenate((class_1_train,class_1_neg),axis = 1) #This is a full literal vector. shape(6742,1568)\n",
    "\n",
    "# combined_train=np.concatenate((class_0_train,class_1_train),axis = 0)  #shape(12665,1584)---5923+6742=12665\n",
    "\n",
    "# class_0_label=np.zeros(class_0_train.shape[0]) #Creating label for class-0\n",
    "# class_1_label=np.ones(class_1_train.shape[0])  #Creating label for class-1\n",
    "# combined_label=np.concatenate((class_0_label,class_1_label),axis=0) #Combine both labels. shape(12665)\n",
    "\n",
    "# train_indices=np.arange(combined_train.shape[0])  #Creates indices of [0,1,2,....12664]\n",
    "# np.random.shuffle(train_indices)                  #Shuffles randomly [23,45,76,....1290]\n",
    "# combined_train=combined_train[train_indices]      #Shuffle data.\n",
    "# combined_label=combined_label[train_indices]      #Shuffle labels.\n",
    "# class_0_neg = 1-class_0_train  #Negated features.\n",
    "# # class_1_neg = 1-class_1_train  #Negated features.\n",
    "\n",
    "# # class_0_literals = np.concatenate((class_0_train,class_0_neg),axis = 1) #This is a full literal vector. shape(5923,1568)---784+784=1568.\n",
    "# # class_1_literals = np.concatenate((class_1_train,class_1_neg),axis = 1)\n",
    "# x_train = combined_train  #Traing literals for training.\n",
    "# y_train = combined_label  #Labels for training.\n",
    "\n",
    "# # Similarly create Testing dataset..\n",
    "\n",
    "# class_0_test=bin(class_0_test)\n",
    "# class_1_test=bin(class_1_test)\n",
    "\n",
    "# class_0_test=class_0_test.reshape(class_0_test.shape[0],-1)\n",
    "# class_1_test=class_1_test.reshape(class_1_test.shape[0],-1)\n",
    "\n",
    "# # class_0_neg=1-class_0_test\n",
    "# # class_1_neg=1-class_1_test\n",
    "\n",
    "# # combined_class_0=np.concatenate((class_0_test,class_0_neg),axis=1)\n",
    "# # combined_class_1=np.concatenate((class_1_test,class_1_neg),axis=1)\n",
    "\n",
    "# combined_test=np.concatenate((class_0_test,class_1_test),axis=0)\n",
    "\n",
    "# class_0_label=np.zeros(class_0_test.shape[0])\n",
    "# class_1_label=np.ones(class_1_test.shape[0])\n",
    "\n",
    "# combined_label=np.concatenate((class_0_label,class_1_label),axis=0)\n",
    "# test_indices=np.arange(combined_label.shape[0])\n",
    "# test_indices\n",
    "# np.random.shuffle(test_indices)\n",
    "\n",
    "# combined_test=combined_test[test_indices]\n",
    "# combined_label=combined_label[test_indices]\n",
    "\n",
    "# x_test=combined_test # Shape(2115,1568)\n",
    "# y_test=combined_label #Shape(2115)\n",
    "\n",
    "# # Training and Testing datasets are ready to see the Machine ..... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ddecfa-4ca7-44be-9b3b-2cf1a935d199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd4241-defc-419d-8a1f-0ad6013e849e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
